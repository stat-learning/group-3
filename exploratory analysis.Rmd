---
title: "Yelp: Exploratory Analysis"
author: "Ryan Kobler"
date: "11/18/2019"
output: pdf_document
---
### Packages:
```{r}
library(jsonlite)
library(tidytext)
library(stringr)
library(wordcloud)
library(wordcloud)
library(dplyr)
library(ggplot2)
```

### Load in the data:
```{r}
#path <- "/Users/ryankobler/Downloads/yelp_review.csv"
#yelp <- read.csv(path)

# Take sample of the data
#yelp %>% sample_frac(0.01)
# Save sample for easy access
#write.csv(df, "yelp-train.csv")
#yelp_review <- read.csv("yelp_review.csv")

# Take sample of the data
#yelp_sample <- yelp_review %>% sample_frac(0.01)
# Save sample for easy access
#write.csv(yelp_sample, "yelp-train.csv")

# Load training data
yelp_train <- read.csv("yelp-train.csv")
yelp_sample <- yelp_train
```

### Count total number of words
```{r}
#count the number of words in the
yelp_sample <- mutate(yelp_sample, numwords = str_count(yelp_sample$text, " "))
#univariate analysis of size
ggplot(data = yelp_sample, aes(x = numwords)) + geom_bar()
#analysis of size vs star rating with locally weighted polynomial
ggplot(data = yelp_sample, aes(x = numwords, y = stars)) + geom_jitter(size = 0.25) + geom_smooth()

```

### Extracting features:
```{r}
# Note: this function requires the tidytext package & drops all
# words that do not convey sentiment
dropStopwords <- function(string){
  # Remove all punctuation except apostrophes & replace with " "
  noPunc <- gsub("[^[:alnum:][:space:]']", " ", string) 
  # Split the larger string by space using strsplit()
  splitBySpace <- unlist(strsplit(noPunc, split = " "))
  # Remove missing chunks
  splitBySpace <- splitBySpace[splitBySpace != ""]
  todrop <- get_stopwords() # query dictionary of stopwords
  todrop <- todrop[[1]]
  splitBySpace[!splitBySpace %in% todrop] # remove stop words
}
# Remove the stop words and save in new column
# yelp_train$prunedtext <- lapply(yelp_train$text, FUN = dropStopwords)


nrc <- get_sentiments("nrc")
get_sentiments("afinn")
get_sentiments("loughran")

```


### Testing on tiny data set
```{r}
yelp.small <- yelp_train[1:3,]
yelp.small$prunedtext <- lapply(yelp.small$text, FUN = dropStopwords)

yelp.small$prunedtext

# Matching sentiments from the NRC dictionary
nrc$sentiment <- as.factor(nrc$sentiment)

# takes sentiment string in nrc and a sequence of pruned words
# associated with 1 review
nrcSentimentCount <- function(senti, text){
  sentiment <- nrc %>% 
  filter(sentiment == senti) %>%
  select(word)
  
  # outputs a count of the number of "trues"
  sum(unlist(text) %in% unlist(sentiment))
}

yelp.small %>% 
  mutate(joy = nrcSentimentCount("fear", prunedtext))

sentiments <- levels(as.factor(nrc$sentiment))

# Generate new columns that count the number of times each sentiment word appears
yelp.small$joy <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "joy")
yelp.small$anger <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "anger")
yelp.small$fear <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "fear")
yelp.small$positive <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "positive")
yelp.small$negative <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "negative")
yelp.small$surprise <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "surprise")
yelp.small$disgust <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "disgust")
yelp.small$trust <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "trust")
yelp.small$anticipation <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "anticipation")
yelp.small$anger <- lapply(yelp.small$prunedtext, nrcSentimentCount, senti = "anger")
```




### Generate word clouds for each rating level

```{r}


```






























