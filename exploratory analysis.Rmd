---
title: "Yelp: Exploratory Analysis"
author: "Ryan Kobler"
date: "11/18/2019"
output: pdf_document
---
### Packages:
```{r}
library(jsonlite)
library(tidytext)
library(stringr)
library(wordcloud)
install.packages("tidyverse")
library(dplyr)
library(ggplot2)

```

### Load in the data:
```{r}
yelp_review <- read.csv("yelp_review.csv")

# Take sample of the data
yelp_sample <- yelp_review %>% sample_frac(0.01)
# Save sample for easy access
write.csv(yelp_sample, "yelp-train.csv")

```
```{r}
#count the number of words in the
yelp_sample <- mutate(yelp_sample, numwords = str_count(yelp_sample$text, " "))
#univariate analysis of size
ggplot(data = yelp_sample, aes(x = numwords)) + geom_bar()
#analysis of size vs star rating with locally weighted polynomial
ggplot(data = yelp_sample, aes(x = numwords, y = stars)) + geom_jitter(size = 0.25) + geom_smooth()

```

### Extracting features:
```{r}
# Note: this function requires the tidytext package & drops all
# words that do not convey sentiment
dropStopwords <- function(string){
  splitBySpace <- unlist(strsplit(test, split = " "))
  todrop <- get_stopwords()
  todrop <- todrop[[1]]
  splitBySpace[!splitBySpace %in% todrop]
}

get_sentiments("nrc")
get_sentiments("afinn")
get_sentiments("loughran")
```